{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building A Handwritten Digits Classifier using Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project machine learning using k-fold cross validation is used to build a handwritten digits classifier.\n",
    "\n",
    "In machine learning normally a dataset is split in a training set to train the model and a test set to validate the model on data it has never seen before. It is common to use a split of 80/20 for the training/test set. When you don't have a large dataset this will result in a small test set which is only 20% of this data. Cross validation is used to overcome this problem. In cross validation the data is splitted more than ones (k times). As a result after all iterations all data is used as test set as can be seen in the figure below where the data is splitted in 6 folds (k=6).\n",
    "\n",
    " <img align=\"left\" src=\"_images/Cross_validation_k6.PNG\">  <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    "\n",
    "Splitting the data in a training and test set used for cross validation can be done in several ways. It is possible to use a standard library or you can write the code yourself. At the start of this project I planned to use the standard library KFold from sklearn, but after a while I was curious if it was possible to write the code myself to get the same result. As a result the k-nearest neighbor algorithm with cross validation is used to build a handwritten digits classifier. For the cross validation the standard library Kfold is used and besides that I wrote the code myself to get the same results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries to be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset with images to be used for the training the machine learning algorithm can be imported from sklearn.datasets using load_digits. The library is imported above and the data is loaded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the digits data and show the array\n",
    "data = load_digits(return_X_y=True)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is loaded in a Numpy 2D array and for further processing it is needed to transform it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5    6    7    8    9   ...   54   55  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  4.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  8.0  0.0   \n",
       "\n",
       "       56   57   58    59    60    61   62   63  \n",
       "0     0.0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3     0.0  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...   ...  ...  ...  \n",
       "1792  0.0  0.0  2.0  14.0  15.0   9.0  0.0  0.0  \n",
       "1793  0.0  0.0  6.0  16.0  14.0   6.0  0.0  0.0  \n",
       "1794  0.0  0.0  2.0   9.0  13.0   6.0  0.0  0.0  \n",
       "1795  0.0  0.0  5.0  12.0  16.0  12.0  0.0  0.0  \n",
       "1796  0.0  1.0  8.0  12.0  14.0  12.0  1.0  0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the Numpy 2D array into a pandas dataframe\n",
    "digits = pd.DataFrame(data[0])\n",
    "target = pd.DataFrame(data[1])\n",
    "tar = target.values.ravel() # create an array with values\n",
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the dataframe above the digits are described with a set of 64 numbers which represent a value on a gray scale. Below for a selection of 9 digits the numbers of the gray scale are transformed into an image, which can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 9 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "C:\\Users\\arnou\\Documents\\Jupiter books\\Building_A_Handwritten_Digits_Classifier_using_Cross_Validation\\_build\\jupyter_execute\\HandwrittenDigitsClassifierUsingCrossValidation_8_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 9 images from the dataframe\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "\n",
    "select_rows = [0,100,200,300,1000,1100,1200,1300, 1400]\n",
    "\n",
    "columns = 3\n",
    "rows = 3\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    first_image = digits.iloc[select_rows[i-1]]\n",
    "    np_image = first_image.values\n",
    "    np_image = np_image.reshape(8,8)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(np_image, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the workflow for k-fold cross validation algorithm is described:\n",
    "\n",
    "- start with splitting the full dataset into k equal length partitions.\n",
    " - selecting k-1 partitions as the training set and\n",
    " - selecting the remaining partition as the test set (values between t0 and t1)\n",
    " \n",
    " <img align=\"left\" src=\"_images/Cross_validation.PNG\">  <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    "\n",
    "- training the model on the training set.\n",
    "- using trained model to predict labels on the test fold.\n",
    "- computing the test fold's error metric.\n",
    "- repeating all of the above steps k-1 times, until each partition has been used as the test set for an iteration.\n",
    "- calculating the mean of the k error values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99333333, 0.98333333, 0.97666667, 0.98662207, 0.98662207,\n",
       "       0.98662207])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for cross validation (k fold cross validation)\n",
    "\n",
    "k = 6\n",
    "def cross_validation(k):\n",
    "    kf = KFold(k, shuffle=True, random_state=1)\n",
    "    knn = KNeighborsClassifier()\n",
    "    mses = cross_val_score(knn, digits, tar, cv=kf)\n",
    "    return mses\n",
    "\n",
    "cross_val_score = cross_validation(k)\n",
    "cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the results for the 6 iterations of the cross validation using the KFold function are shown. Below the function is written by myself and the results are the same as from the workflow above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9933333333333333,\n",
       " 0.9833333333333333,\n",
       " 0.9766666666666667,\n",
       " 0.9866220735785953,\n",
       " 0.9866220735785953,\n",
       " 0.9866220735785953]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Workflow for k-fold cross validation\n",
    "k = 6\n",
    "\n",
    "# function for training k-nn models\n",
    "\n",
    "def training(train, target):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(train, target)\n",
    "    return knn \n",
    "\n",
    "# function for test k-nn models\n",
    "\n",
    "def testing(knn, test_set):\n",
    "    predictions = knn.predict(test_set)\n",
    "    return predictions\n",
    "\n",
    "# function for cross validation (k fold cross validation)\n",
    "\n",
    "def cross_validation(k):\n",
    "    result = []\n",
    "    predictions = []\n",
    "    y_test_list = []\n",
    "    t0 = 0\n",
    "    t1 = 0\n",
    "    for i in range(k):\n",
    "        #Determine the size to be used for splitting the dataset\n",
    "        step = (len(digits)-t1) / (k - i)\n",
    "        t1 += int(math.ceil(step))\n",
    "        new_step = t1-t0        \n",
    "        \n",
    "        #shuffle the digits en tar dataset\n",
    "        digits_shuffled, tar_shuffled = shuffle(digits, tar, random_state=1)\n",
    "        \n",
    "        #Create the train en test sets (X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        #for X_train select values < t0 and > t1 and concatenate the data\n",
    "        X0 = digits_shuffled[:t0]\n",
    "        X1 = digits_shuffled[t1:]\n",
    "        frames = [X0, X1]\n",
    "        X_train = pd.concat(frames)\n",
    "        \n",
    "        #for y_train select values < t0 and > t1 and concatenate the data\n",
    "        y0 = tar_shuffled[:t0]\n",
    "        y1 = tar_shuffled[t1:]\n",
    "        frames_y = [y0, y1]\n",
    "        y_train = np.concatenate(frames_y)\n",
    "        \n",
    "        #for the test set select values between t0 and t1\n",
    "        X_test = digits_shuffled[t0:t1]\n",
    "        y_test = tar_shuffled[t0:t1]\n",
    "        \n",
    "        #train en test the model\n",
    "        model = training(X_train, y_train)\n",
    "        prediction = testing(model, X_test)\n",
    "        correct = prediction - y_test\n",
    "        number_correct = len(correct[correct==0])/new_step\n",
    "        \n",
    "        #store the results to be returned in the end\n",
    "        result.append(number_correct)\n",
    "        predictions.append(prediction)\n",
    "        y_test_list.append(y_test)\n",
    "        \n",
    "        #Set t0 for the next iteration\n",
    "        t0 = t1\n",
    "    return result, predictions, y_test_list\n",
    "\n",
    "result_tot, predict_y, y_test_list = cross_validation(k)\n",
    "result_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the score of the 6 iterations is present. The next step is to calculate the mean of the 6 error values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9855332590115199"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of the k error values\n",
    "mean_score = np.mean(result_tot)\n",
    "mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the mean error value, it is interesting to see which digit is not predicted correctly. Below a list is shown of the predictions which are not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1032</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1089</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1371</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1388</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1448</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1515</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1577</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1633</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions  y_test\n",
       "249             9       7\n",
       "298             7       2\n",
       "462             5       1\n",
       "523             1       8\n",
       "537             5       9\n",
       "540             8       9\n",
       "576             1       9\n",
       "609             3       9\n",
       "635             7       3\n",
       "648             3       9\n",
       "683             6       5\n",
       "748             3       8\n",
       "768             7       4\n",
       "799             3       9\n",
       "957             9       5\n",
       "1032            8       6\n",
       "1089            4       9\n",
       "1090            7       3\n",
       "1336            8       3\n",
       "1371            1       8\n",
       "1388            8       4\n",
       "1448            7       4\n",
       "1515            1       8\n",
       "1577            1       8\n",
       "1633            1       8\n",
       "1786            1       8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions vs expected results from the testset\n",
    "\n",
    "predict_y = np.concatenate(predict_y)\n",
    "y_test_list = np.concatenate(y_test_list)\n",
    "\n",
    "predict_result = pd.DataFrame(predict_y, columns=['predictions'])\n",
    "predict_result['y_test']=y_test_list\n",
    "\n",
    "# select the items where the prediction is not equal to the expected result\n",
    "wrong = predict_result[predict_result['predictions'] != predict_result['y_test']]\n",
    "wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above the 26 results out of 1797 are shown which are not predicted correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project machine learning using k-fold cross validation is used to build a handwritten digits classifier. \n",
    "The k-fold cross validation is demonstrated using the KFold function from sklearn and it is compared to a workflow written by myself to get the same results. As the outcome of both methods is the same, it can be concluded that it is possible to write your own code to create a workflow for cross validation. It was a nice learning experience for me to get more insights of the internals of a standard function like KFold.\n",
    "The algorithm which is built in this project can predict a digit which is correct in 98.55% of the cases.\n",
    "\n",
    "Next steps:\n",
    "- Try making changes in the workflow to improve correct predictions percentage\n",
    "- Use the existing pipeline to try other machine learning models like Decision Tree Models or Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}